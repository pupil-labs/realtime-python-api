# Under The Hood

This guide explains how the Pupil Labs' Realtime API works on the wire and how this
client library abstracts away some of the complexities of the underlying protocols.

## HTTP REST API

The Neon / Pupil Invisible Companion app hosts an [HTTP REST API](https://restfulapi.net/)
that can be used to query the phone's current state, remote control it, and look up
information about available data streams.

By default, the API is hosted at `http://neon.local:8080/` or `http://pi.local:8080/`.
The app will fallback to a different DNS name and/or port if the default values are taken by another app
already. The current connection details can be looked up under the app's main menu â†’
Streaming. Alternatively, you can use [Service discovery in the local network](#service-discovery-in-the-local-network) to find
available devices.

!!! note
The device serves the built-in monitor web app at the
document root `/`. The API is served under the `/api` path. You can find the
full [OpenAPI 3](https://swagger.io/specification/) specification of the REST API
[here](https://pupil-labs.github.io/realtime-network-api/).

### Start/stop/cancel recordings

By sending [HTTP POST](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST)
requests to the `/api/recording:*` endpoints, you can start, stop, and cancel
recordings.

-   `POST /api/recording:start` - Starts a recording if possible
-   `POST /api/recording:stop_and_save` - Stops and saves the running recording if possible
-   `POST /api/recording:cancel` - Stops and discards the running recording if possible

!!! attention
In specific situations, the app will not comply with the request to start a new
recording:

    - the selected template has required fields
    - the available storage amount is too low
    - the device battery is too low
    - no wearer has been selected
    - no workspace has been selected
    - the setup bottom sheets have not been completed

!!! seealso
**`simple` blocking implementations**

    - `pupil_labs.realtime_api.simple.Device.recording_start`
    - `pupil_labs.realtime_api.simple.Device.recording_stop_and_save`
    - `pupil_labs.realtime_api.simple.Device.recording_cancel`

    **Asynchronous implementations**

    - `pupil_labs.realtime_api.device.Device.recording_start`
    - `pupil_labs.realtime_api.device.Device.recording_stop_and_save`
    - `pupil_labs.realtime_api.device.Device.recording_cancel`

### Send events

By [HTTP POSTing](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST)
requests to the `/api/event` endpoint, you can send labeled events to the device.
Events will be timestamped on reception. Alternatively, you can provide a Unix-epoch
timestamp in nanosecond. This is recommended if you want to control the timing of the
event.

-   `POST /api/event` - Sends an event to the device

!!! seealso
**Implementations**

    - `simple` blocking: `pupil_labs.realtime_api.simple.Device.send_event`
    - Asynchronous: `pupil_labs.realtime_api.device.Device.send_event`

### Get Current Status

By sending a [HTTP GET](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET)
request to the `/api/status` endpoint, you can receive information about the device's
current status. This includes information about the battery and storage capacities,
connected sensors, and running recordings.

-   `GET /api/status` - Receive status from device

!!! seealso
Asynchronous implementations: `pupil_labs.realtime_api.device.Device.get_status`

## Websocket API

In addition to the HTTP REST API above, the Neon / Pupil Invisible Companion device also
pushes status updates via a [websocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) connection. It is
hosted on the same port as the REST API. By default, you can connect to it via
`ws://neon.local:8080/api/status` or `ws://pi.local:8080/api/status`.

!!! tip
You can use this [website](http://livepersoninc.github.io/ws-test-page/) to test
the websocket connection.

The messages published via this connection have the same format as the [Get Current Status](#get-current-status) endpoint.

## Streaming API

The Neon / Pupil Invisible Companion app uses the RTSP protocol ([RFC 2326](https://datatracker.ietf.org/doc/html/rfc2326)) to stream scene video and gaze data.
Under the hood, communication is three-fold:

-   [RTSP](#rtsp) (RealTime Streaming Protocol) - Provides meta data about the corresponding stream
-   [RTP](#rtp) (Realtime Transport Protocol) - Data delivery channel, contains actual payloads
-   [RTCP](#rtcp) (RTP Control Protocol) - Provides absolute time information to align multiple streams

The necessary connection information is made available via the [Sensor model](https://github.com/pupil-labs/realtime-network-api/blob/main/openapi_specification.yaml#L281)
as part of the [Get Current Status](#get-current-status) and [Websocket API](#websocket-api).

The RTSP connection URL follows the following pattern:

```
rtsp://<ip>:<port>/?<params>
```

!!! caution
Each stream is available via two connection types:

    - `DIRECT` - direct RTSP connection, as described in this document
    - `WEBSOCKET` - tunneling RTSP over a websocket connection to make it
      available to web browsers

!!! seealso
The Realtime Network API exposes this information via
`pupil_labs.realtime_api.models.Status.direct_world_sensor` and
`pupil_labs.realtime_api.models.Status.direct_gaze_sensor`, returning
`pupil_labs.realtime_api.models.Sensor` instances.

### RTSP

The Real Time Streaming Protocol, or RTSP, is an application-level protocol for
control over the delivery of data with real-time properties.

Source: [https://datatracker.ietf.org/doc/html/rfc2326](https://datatracker.ietf.org/doc/html/rfc2326)

Of the various [methods](https://datatracker.ietf.org/doc/html/rfc2326#section-6.1)
defined in the RTSP protocol, [SETUP](https://datatracker.ietf.org/doc/html/rfc2326#section-10.4)
and [DESCRIBE](https://datatracker.ietf.org/doc/html/rfc2326#section-10.2) are
particularly important for the transmission of the stream's meta and connection
information.

During the SETUP method, client and server exchange information about their
corresponding port numbers for the [RTP](#rtp) and [RTCP](#rtcp) connections.

The DESCRIBE response contains [SDP](https://datatracker.ietf.org/doc/html/rfc2326#page-80)
(Session Description Protocol) data, describing the following stream attributes (via the
[media's rtpmap](https://datatracker.ietf.org/doc/html/rfc2326#appendix-C.1.3)):

-   `encoding` - The encoding of the stream, e.g. `H264`
-   `clockRate` - The clock rate of the stream's relative clock

For video, it also exposes the [sprop-parameter-sets](https://datatracker.ietf.org/doc/html/rfc6184#section-8.2.1) via its [format-specific
parameters](https://datatracker.ietf.org/doc/html/rfc5576#section-6.3) (`fmtp`).
These contain crucial information in order to initialize the corresponding video decoder.

!!! attention
Each stream has its own clock rate. For temporal alignment, the clock offset between
the stream's relative clock and the absolute NTP clock has to be calculated. See
[RTCP](#rtcp) below.

!!! seealso
To encode gaze data, a custom encoding called `com.pupillabs.gaze1` is used.
You can find more information about it below.

### RTP

[The real-time transport protocol] provides end-to-end network transport functions
suitable for applications transmitting real-time data, such as audio, video or
simulation data, over multicast or unicast network services. [...] The data
transport is augmented by a control protocol ([RTCP](#rtcp)) [...]. [RTP](#rtp) and [RTCP](#rtcp) are
designed to be independent of the underlying transport and network layers.

Source: [https://datatracker.ietf.org/doc/html/rfc3550](https://datatracker.ietf.org/doc/html/rfc3550)

Payloads can be split across multiple RTP packets. Their order can be identified via the
packet header's [sequence number](https://datatracker.ietf.org/doc/html/rfc1889#section-5.1).
Packets belonging to the same payload have the same timestamp. The payloads can be
decoded individually. See [Decoding Gaze Data](#decoding-gaze-data) and [Decoding Video Data](#decoding-video-data) below.

!!! seealso - Read more about the RTP timestamp mechanism [here](https://datatracker.ietf.org/doc/html/rfc1889#section-5.1). - The Realtime Python API exposes raw RTP data via
`pupil_labs.realtime_api.streaming.base.RTSPRawStreamer.receive` and
calculates relative RTP packet timestamps in
`pupil_labs.realtime_api.streaming.base._WallclockRTSPReader.relative_timestamp_from_packet`.

### RTCP

The most important role that the RTP control protocol plays for the Pupil Labs Realtime
Network API is to provide timestamps in relative stream time and in absolute NTP time
([SR RTCP Packet type](https://datatracker.ietf.org/doc/html/rfc1889#section-6.1)).

Relative timestamps are calculated by dividing the packet timestamp (numerator) by the
clock rate (denominator), e.g. a timestamp of 250 at a clock rate of 50 Hz corresponds
to `250 / 50 = 5` seconds.

Wallclock time (absolute date and time) is represented using the timestamp format of
the [Network Time Protocol](https://datatracker.ietf.org/doc/html/rfc1305) (NTP),
which is in seconds relative to 1 January **1900** 00:00:00 UTC. The full resolution
NTP timestamp is a 64-bit unsigned fixed-point number with the integer part in the
first 32 bits and the fractional part in the last 32 bits.

Source: [https://datatracker.ietf.org/doc/html/rfc3550#section-4](https://datatracker.ietf.org/doc/html/rfc3550#section-4)

Knowing time points in both corresponding clocks, relative and absolute one, allows one
to calculate the clock offset between the two clocks. This is done by subtracting the
one from the other. The offset is then added to new relative timestamps to get the
corresponding time.

!!! attention
The Realtime Python API converts absolute NTP timestamps to nanoseconds in **Unix**
epoch (time since 1 January **1970** 00:00:00 UTC). This corresponds to the same
time base and unit returned by `time.time_ns`.

### Decoding Gaze Data

Gaze data is encoded in network byte order (big-endian) and consists of:

1. `x` - Horizontal component of the gaze location in pixels within the scene camera's
   coordinate system. The value is encoded as a 32-bit float.
2. `y` - Vertical component of the gaze location in pixels within the scene camera's
   coordinate system. The value is encoded as a 32-bit float.
3. `worn` - Boolean indicating whether the user is wearing the device. The value is
   encoded as an unsigned 8-bit integer as either `255` (device is being worn) or `0` (device is _not_ being worn).

**Eye State Data (Optional)**

If eye state computation is enabled (not available for Pupil Invisible), additional parameters are included(all encoded as a 32-bit float):

4. **`pupil_diameter_left`**: Physical diameter of the left pupil in millimetres.
5. **`eyeball_center_left_x`**: X-coordinate of the left eyeball centre relative to the scene camera.
6. **`eyeball_center_left_y`**: Y-coordinate of the left eyeball centre relative to the scene camera.
7. **`eyeball_center_left_z`**: Z-coordinate of the left eyeball centre relative to the scene camera.
8. **`optical_axis_left_x`**: X-component of the left eye's optical axis vector.
9. **`optical_axis_left_y`**: Y-component of the left eye's optical axis vector.
10. **`optical_axis_left_z`**: Z-component of the left eye's optical axis vector.
11. **`pupil_diameter_right`**: Physical diameter of the right pupil in millimetres.
12. **`eyeball_center_right_x`**: X-coordinate of the right eyeball centre relative to the scene camera.
13. **`eyeball_center_right_y`**: Y-coordinate of the right eyeball centre relative to the scene camera.
14. **`eyeball_center_right_z`**: Z-coordinate of the right eyeball centre relative to the scene camera.
15. **`optical_axis_right_x`**: X-component of the right eye's optical axis vector.
16. **`optical_axis_right_y`**: Y-component of the right eye's optical axis vector.
17. **`optical_axis_right_z`**: Z-component of the right eye's optical axis vector.
18. **`timestamp_unix_seconds`**: Unix timestamp representing the time of data capture.

Each RTP packet contains one gaze datum. The payload length varies:

-   **21 bytes**: When only gaze data is included. To unpack - (!ffB)
-   **77 bytes**: When both gaze and eye state data are included. To unpack - (!ffBffffffffffffff)

!!! tip
RTSP packets can be captured and analysed using **Wireshark**, a comprehensive network protocol analyser.
This tool allows detailed inspection of packet data for in-depth analysis and troubleshooting.

!!! seealso
The Realtime Python API exposes gaze data via
`pupil_labs.realtime_api.streaming.gaze.RTSPGazeStreamer.receive` and
`pupil_labs.realtime_api.streaming.gaze`.

### Decoding Video Data

Video frames are split across multiple RTP packets. The payload is wrapped in the
additional [Network Abstraction Layer](https://datatracker.ietf.org/doc/html/rfc6184#section-5.3)
(NAL). This allows finding frame boundaries across fragmented payloads without relying
on the RTP meta information.

Once the data is unpacked from the NAL, it can be passed to a corresponding video
decoder, e.g. `pyav's av.CodecContext`.

!!! important
The video decoder needs to be initialized with the [sprop-parameter-sets](https://datatracker.ietf.org/doc/html/rfc6184#section-8.2.1) exposed via the
[RTSP](#rtsp) DESCRIBE method.

!!! seealso
The Realtime Python API implements the NAL unpacking here:
`pupil_labs.realtime_api.streaming.nal_unit.extract_payload_from_nal_unit`

## Service discovery in the local network

To avoid having to manually copy the IP address from the Neon / Pupil Invisible Companion user
interface, the application announces its REST API endpoint via [multicast DNS service
discovery](https://en.wikipedia.org/wiki/Zero-configuration_networking#DNS-SD_with_multicast).
Specifically, it announces a service of type `_http._tcp.local.` and uses the following
naming pattern:

```
PI monitor:<phone name>:<phone hardware id>._http._tcp.local.
```

!!! seealso - The service name is exposed via - `pupil_labs.realtime_api.models.DiscoveredDeviceInfo.name` and - `pupil_labs.realtime_api.base.DeviceBase.full_name`. - The phone name component is exposed via - `pupil_labs.realtime_api.models.Phone.device_name` and - `pupil_labs.realtime_api.simple.Device.phone_name`. - The phone hardware id component is exposed via - `pupil_labs.realtime_api.models.Phone.device_id` and - `pupil_labs.realtime_api.simple.Device.phone_id`.

The client's `pupil_labs.realtime_api.discovery` module uses the
`zeroconf` Python package under the hood to discover services.
